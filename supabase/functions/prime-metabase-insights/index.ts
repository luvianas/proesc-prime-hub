// Supabase Edge Function: prime-metabase-insights
// Fetches data from Metabase (card query) and asks OpenAI GPT-5 Mini to explain/interpret it.

interface RequestPayload {
  question: string;
  screenshot?: string; // Base64 encoded image
  cardId?: number;
  params?: Record<string, unknown>;
  dashboardUrl?: string;
  locale?: string;
  dashboardType?: 'financeiro' | 'agenda' | 'secretaria' | 'pedagogico';
}

interface MetabaseResult {
  rows?: any[];
  cols?: { name: string }[];
  data?: {
    rows?: any[];
    cols?: { name: string }[];
    columns?: { name: string }[];
  };
}

const json = (body: any, init: ResponseInit = {}) =>
  new Response(JSON.stringify(body), {
    headers: {
      "content-type": "application/json",
      "access-control-allow-origin": "*",
      "access-control-allow-headers": "*",
    },
    ...init,
  });

Deno.serve(async (req) => {
  if (req.method === "OPTIONS") {
    return new Response(null, {
      headers: {
        "access-control-allow-origin": "*",
        "access-control-allow-headers": "*",
        "access-control-allow-methods": "POST, OPTIONS",
      },
    });
  }

  try {
    const { question, screenshot, cardId, params, dashboardUrl, locale, dashboardType }: RequestPayload = await req.json();
    if (!question || typeof question !== "string") {
      return json({ error: "Missing 'question'" }, { status: 400 });
    }
    
    if (!screenshot || typeof screenshot !== "string") {
      return json({ error: "Missing 'screenshot' - dashboard image required" }, { status: 400 });
    }

    const METABASE_SITE_URL = Deno.env.get("METABASE_SITE_URL");
    const METABASE_TOKEN = Deno.env.get("METABASE_TOKEN");
    const METABASE_SESSION = Deno.env.get("METABASE_SESSION");
    const OPENAI_API_KEY = Deno.env.get("OPENAI_API_KEY");

    if (!OPENAI_API_KEY) {
      return json({ error: "OPENAI_API_KEY not configured" }, { status: 500 });
    }

    let columns: string[] = [];
    let sampleRows: any[] = [];
    let hasMetabaseData = false;
    let dataConfidence = 0;
    let issuesFound: string[] = [];

    console.log("=== DEBUG INFO ===");
    console.log("dashboardType:", dashboardType || "none");
    console.log("params:", params ? JSON.stringify(params) : "none");
    console.log("screenshot size:", screenshot ? `${Math.round(screenshot.length / 1024)}KB` : "none");
    
    // Using screenshot-based analysis (no Metabase required)
    hasMetabaseData = true; // We have visual data
    dataConfidence = 85; // High confidence with visual analysis
    console.log("Using screenshot-based analysis with GPT-5 Vision");

    // Build context-specific prompts
    const getContextualPrompt = (type?: string) => {
      const basePrompt = `Voc√™ √© um analista de dados especializado do Proesc Prime, com expertise em an√°lise educacional e gest√£o escolar.
      
‚ö†Ô∏è **IMPORTANTE**: Analise SOMENTE os dados que est√£o sendo exibidos no dashboard atual com os filtros aplicados. N√ÉO fa√ßa an√°lises gerais da escola.`;
      
      const contextPrompts: Record<string, string> = {
        'financeiro': `${basePrompt}\n\nüè¶ **AN√ÅLISE FINANCEIRA DOS DADOS FILTRADOS**\nAnalise especificamente os dados financeiros apresentados no dashboard com os filtros atuais aplicados:`,
        'agenda': `${basePrompt}\n\nüìÖ **AN√ÅLISE DOS AGENDAMENTOS FILTRADOS**\nAnalise especificamente os dados de agenda apresentados no dashboard com os filtros atuais aplicados:`,
        'secretaria': `${basePrompt}\n\nüìã **AN√ÅLISE ADMINISTRATIVA DOS DADOS FILTRADOS**\nAnalise especificamente os dados administrativos apresentados no dashboard com os filtros atuais aplicados:`,
        'pedagogico': `${basePrompt}\n\nüéì **AN√ÅLISE PEDAG√ìGICA DOS DADOS FILTRADOS**\nAnalise especificamente os dados pedag√≥gicos apresentados no dashboard com os filtros atuais aplicados:`
      };

      return contextPrompts[type || ''] || `${basePrompt}\n\nüìä **AN√ÅLISE DOS DADOS FILTRADOS**\nAnalise especificamente os dados apresentados no dashboard com os filtros atuais:`;
    };

    const systemPrompt = [
      getContextualPrompt(dashboardType),
      `\nüìã **ESTRUTURA DA AN√ÅLISE (FOCO NOS DADOS FILTRADOS):**`,
      `\nüéØ **RESUMO DOS DADOS ATUAIS**`,
      `‚Ä¢ Identifique claramente o per√≠odo/escopo dos dados (ex: "m√™s de X", "turma Y", etc.)`,
      `‚Ä¢ Mencione os filtros ativos que definem este conjunto de dados`,
      `‚Ä¢ Principal conclus√£o espec√≠fica dos dados em tela`,
      `\nüìà **AN√ÅLISE DOS DADOS APRESENTADOS**`,
      `‚Ä¢ Interprete APENAS as m√©tricas vis√≠veis no dashboard atual`,
      `‚Ä¢ Identifique padr√µes dentro do conjunto de dados filtrado`,
      `‚Ä¢ Compare valores apenas dentro do escopo atual (se aplic√°vel)`,
      `\n‚ö†Ô∏è **INSIGHTS DOS DADOS ESPEC√çFICOS**`,
      `‚Ä¢ Destaque pontos importantes dos dados filtrados`,
      `‚Ä¢ Identifique oportunidades baseadas no conjunto atual`,
      `‚Ä¢ Sinalize alertas espec√≠ficos do per√≠odo/segmento analisado`,
      `\nüí° **A√á√ïES PARA ESTE CONTEXTO ESPEC√çFICO**`,
      `‚Ä¢ 3-4 a√ß√µes pr√°ticas baseadas nos dados atuais em tela`,
      `‚Ä¢ Recomenda√ß√µes espec√≠ficas para o per√≠odo/filtro aplicado`,
      `‚Ä¢ Sugest√µes de filtros adicionais para aprofundar esta an√°lise`,
      `\nüéØ **SEJA ESPEC√çFICO**: Sempre referencie que est√° analisando os dados com filtros atuais, n√£o a escola inteira.`,
      `üìä **Use os n√∫meros exatos dos dados apresentados no dashboard.**`
    ].join("\n");

    const contextParts: string[] = [];
    
    contextParts.push(`üì∏ **AN√ÅLISE VISUAL**: Voc√™ est√° analisando uma captura de tela do dashboard em tempo real.`);
    
    if (params && Object.keys(params).length > 0) {
      contextParts.push(`üîß **FILTROS APLICADOS**: ${JSON.stringify(params, null, 2)}`);
    }
    
    if (dashboardType) {
      contextParts.push(`üìä **TIPO DE DASHBOARD**: ${dashboardType}`);
    }

    const fullPrompt = [
      systemPrompt,
      `\nüîç **Pergunta**: ${question}`,
      `\nüìã **Contexto**:\n${contextParts.join("\n")}`,
      `\nüéØ **INSTRU√á√ïES IMPORTANTES**:`,
      `‚Ä¢ Analise TODOS os gr√°ficos, tabelas e n√∫meros vis√≠veis na imagem`,
      `‚Ä¢ Identifique padr√µes, tend√™ncias e anomalias nos dados visualizados`,
      `‚Ä¢ Cite valores espec√≠ficos que voc√™ consegue ler nos gr√°ficos`,
      `‚Ä¢ Se houver legendas, t√≠tulos ou r√≥tulos, use-os na an√°lise`,
      locale ? `\nüåç Idioma: ${locale}` : '',
    ].filter(Boolean).join("\n");

    // ‚úÖ Using OpenAI GPT-5 with Vision
    const openaiEndpoint = "https://api.openai.com/v1/chat/completions";
    
    console.log("ü§ñ Using OpenAI GPT-5 with Vision");
    console.log("üåê OpenAI endpoint:", openaiEndpoint);
    
    const aiRes = await fetch(openaiEndpoint, {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${OPENAI_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "gpt-5-2025-08-07", // GPT-5 supports vision
        messages: [
          {
            role: "system",
            content: "Voc√™ √© um assistente especializado em an√°lise de dados educacionais e dashboards do Proesc Prime com capacidade de an√°lise visual de gr√°ficos e tabelas."
          },
          {
            role: "user",
            content: [
              {
                type: "text",
                text: fullPrompt
              },
              {
                type: "image_url",
                image_url: {
                  url: screenshot, // Base64 data URL
                  detail: "high" // High detail for better analysis
                }
              }
            ]
          }
        ],
        max_completion_tokens: 2048, // More tokens for detailed visual analysis
        // Note: GPT-5 does not support temperature parameter (always 1.0)
      }),
    });
    
    console.log("ü§ñ OpenAI response status:", aiRes.status);

    if (!aiRes.ok) {
      const errorText = await aiRes.text();
      console.error("‚ùå OpenAI API error:", aiRes.status, errorText);
      return json({ 
        error: "Erro na API do OpenAI", 
        details: errorText,
        suggestion: "Verifique se a chave OPENAI_API_KEY est√° correta e ativa"
      }, { status: 500 });
    }

    const aiJson = await aiRes.json();
    
    // OpenAI returns response in choices[0].message.content format
    let answer = "";
    if (aiJson.choices && aiJson.choices.length > 0) {
      answer = aiJson.choices[0].message.content || "N√£o foi poss√≠vel gerar uma resposta.";
    } else {
      console.error("Unexpected OpenAI response structure:", JSON.stringify(aiJson));
      answer = "Erro ao processar resposta da IA.";
    }

    console.log("‚úÖ Analysis completed");
    
    return json({
      answer,
      dataQuality: {
        hasMetabaseData: true, // Visual analysis
        confidence: dataConfidence,
        metabaseStatus: 'visual_analysis',
        issues: issuesFound
      },
      metadata: {
        analysisType: 'screenshot',
        screenshotSize: Math.round(screenshot.length / 1024) + 'KB',
        dashboardType: dashboardType || null,
        timestamp: new Date().toISOString()
      },
    });
  } catch (e: any) {
    console.error("Function error:", e);
    return json({ error: e?.message || "Unexpected error" }, { status: 500 });
  }
});
